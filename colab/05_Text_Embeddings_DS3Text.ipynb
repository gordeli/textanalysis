{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/steve-wilson/ds32019/blob/master/05_Text_Embeddings_DS3Text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "APfI_c8B40Vn"
   },
   "source": [
    "#Fundamentals of Text Analysis for User Generated Content @ EDHEC, 2021\n",
    "\n",
    "# Part 5: Text Embeddings\n",
    "\n",
    "[<- Previous: Content Analysis](https://colab.research.google.com/github/gordeli/textanalysis/blob/master/colab/04_Text_Processsing_Basics_DS3Text.ipynb)\n",
    "\n",
    "[-> Next: Machine Learning](https://colab.research.google.com/github/gordeli/textanalysis/blob/master/colab/06_Text_Processsing_Basics_DS3Text.ipynb)\n",
    "\n",
    "Dates: February 8 - 15, 2021\n",
    "\n",
    "Facilitator: [Ivan Gordeliy](https://www.linkedin.com/in/gordeli/)\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cdTajgZhkGWX"
   },
   "source": [
    "## Initial Setup\n",
    "\n",
    "- **Run \"Setup\" below first.**\n",
    "\n",
    "    - This will load libraries and download some resources that we'll use throughout the tutorial.\n",
    "\n",
    "    - You will see a message reading \"Done with setup!\" when this process completes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKVEnPi34qj4"
   },
   "outputs": [],
   "source": [
    "#@title Setup (click the \"run\" button to the left) {display-mode: \"form\"}\n",
    "\n",
    "## Setup ##\n",
    "\n",
    "# imports\n",
    "\n",
    "# built-in Python libraries\n",
    "# -------------------------\n",
    "\n",
    "# for defaultdict data structure\n",
    "import collections\n",
    "# for reading csv files\n",
    "import csv\n",
    "# operating system functions\n",
    "import os\n",
    "\n",
    "# 3rd party libraries\n",
    "# -------------------\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "! pip install --upgrade gensim\n",
    "import gensim\n",
    "import gensim.test.utils\n",
    "import gensim.scripts.glove2word2vec\n",
    "import gensim.models.fasttext\n",
    "\n",
    "import scipy.spatial.distance\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "! pip install fasttext\n",
    "import fasttext\n",
    "\n",
    "if not os.path.exists(\"glove.twitter.27B.zip\"):\n",
    "    !wget http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
    "else:\n",
    "    print(\"GloVe already downloaded.\")\n",
    "if not os.path.exists(\"glove.twitter.27B.50d.txt\"):\n",
    "    !unzip glove.twitter.27B.zip\n",
    "else:\n",
    "    print(\"GloVe already extracted.\")\n",
    "if not os.path.exists(\"questions-words.txt\"):\n",
    "    !wget http://download.tensorflow.org/data/questions-words.txt\n",
    "else:\n",
    "    print(\"Word analogies data already loaded.\")\n",
    "if not os.path.exists(\"crawl-300d-2M-subword.zip\"):\n",
    "    !wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M-subword.zip\n",
    "else:\n",
    "    print(\"Fasttext embeddings already downloaded\")\n",
    "if not os.path.exists(\"crawl-300d-2M-subword.vec\"):\n",
    "    print(\"Extracting Fasttext embeddings. This may take several minutes...\")\n",
    "    !unzip crawl-300d-2M-subword.zip\n",
    "else:\n",
    "    print(\"Fasttext already extracted.\")\n",
    "if not os.path.exists(\"Stsbenchmark.tar.gz\"):\n",
    "    !wget http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz\n",
    "    !tar -xzf Stsbenchmark.tar.gz\n",
    "print()\n",
    "print(\"Done with setup!\")\n",
    "print(\"If you'd like, you can click the (X) button to the left to clear this output.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ah3YPx-h7Rjt"
   },
   "source": [
    "---\n",
    "\n",
    "## A - Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sc9vfbk_7UXY"
   },
   "source": [
    "### Using gensim for word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SKRZDcr0mB6G"
   },
   "source": [
    "- Gensim is back: this time we'll use it to experiment with word embeddings.\n",
    "- We can use it to load an embeddings matrix in several formats.\n",
    "    - Since we've been working with some social media data, let's load the GloVe Twitter embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-vIv8CnH7agl"
   },
   "outputs": [],
   "source": [
    "# Load 100-dimensional vectors\n",
    "glove_file_path = \"glove.twitter.27B.100d.txt\"\n",
    "# First convert to word2vec format (what gensim expects)\n",
    "tmp_file_path = gensim.test.utils.get_tmpfile(\"word2vec_twitter_100d.txt\")\n",
    "_ = gensim.scripts.glove2word2vec.glove2word2vec(glove_file_path, tmp_file_path)\n",
    "\n",
    "# Now load with gensim (may take several minutes)\n",
    "print(\"Loading GloVe...\")\n",
    "glove = gensim.models.KeyedVectors.load_word2vec_format(tmp_file_path)\n",
    "print(\"GloVe was loaded into memory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pR4R-6qmrgXK"
   },
   "source": [
    "- **Now, what can we do with these embeddings?**\n",
    "- Find the most similar words to a query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d20vsWL6rTxL"
   },
   "outputs": [],
   "source": [
    "glove.most_similar(\"france\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KEQn5rTzrnun"
   },
   "source": [
    "- Measure similarity between any pair of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AXPm1rdcrwqZ"
   },
   "outputs": [],
   "source": [
    "pairs = [ ('data','pastry') , ('beautiful','lovely'), ('hot','cold'), \\\n",
    "          ('a person walked their dog','a dog walked with a person') , \\\n",
    "          ('the school was prestigious','the university was highly ranked')]\n",
    "\n",
    "for pair in pairs:\n",
    "    sim = glove.n_similarity(pair[0].split(),pair[1].split())\n",
    "    print(pair,\":\",sim)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eS3xEW7mwnUN"
   },
   "source": [
    "- Or just get the vector representation for a word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GglQMqgIwukb"
   },
   "outputs": [],
   "source": [
    "vector = glove['summer']\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UkAh9Rta7bQa"
   },
   "source": [
    "### Word embedding geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8jCqP5XoxQWV"
   },
   "source": [
    "- The classic example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tgNhMhKe7fr8"
   },
   "outputs": [],
   "source": [
    "mystery_word_vec = glove['king'] - glove['man'] + glove['woman']\n",
    "glove.similar_by_vector(mystery_word_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fKujVo2V8Lvs"
   },
   "source": [
    "### Putting it together: word analogies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5-NLjfd81Kyd"
   },
   "source": [
    "- In the not-too-distance past, these types of questions appeared on American college entrance examinations:\n",
    "    - e.g., \"man:king::woman:?\"\n",
    "        - answer: queen\n",
    "- Around 2013, when word vectors were becoming extremely popular, this task was studied within the NLP community, and along with it came some standard datasets.\n",
    "    Let's load one of them here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cofHFFz01KTt"
   },
   "outputs": [],
   "source": [
    "analogies = collections.defaultdict(list)\n",
    "category = \"\"\n",
    "with open(\"questions-words.txt\",'r') as analogy_questions:\n",
    "    for aq in analogy_questions:\n",
    "        if aq.startswith(\":\"):\n",
    "            category = aq.split(\":\")[1].strip()\n",
    "        else:\n",
    "            a,b,c,d = aq.split()\n",
    "            analogies[category].append([a,b,c,d])\n",
    "            \n",
    "print(\"Loaded analogies with\",len(analogies),\"categories.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "drLyYe0cyXur"
   },
   "source": [
    "**Exercise 6**: Word analogies\n",
    "- Using the GloVe embeddings that we loaded before, write a function to complete word analogies.\n",
    "    - return a list of the top `top_n` guesses, in order from most likely to least likely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ty58G36u8Qlj"
   },
   "outputs": [],
   "source": [
    "# solve an analogy a is to b as c is to ?\n",
    "def guess_analogy(a,b,c,vectors,top_n=5):\n",
    "    \n",
    "# ------------- Exercise 6 -------------- #\n",
    "\n",
    "\n",
    "    return []\n",
    "# ---------------- End ------------------ #\n",
    "    \n",
    "\n",
    "# quick test\n",
    "a,b,c,d = \"man\",\"king\",\"woman\",\"queen\"\n",
    "guesses = guess_analogy(a,b,c,glove)\n",
    "if d in guesses:\n",
    "    print(\"queen was in the top n guesses!\")\n",
    "else:\n",
    "    print(\"queen was NOT in the top n guesses...\")\n",
    "    print(\"guesses were:\",guesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EEBf9kApyLCA"
   },
   "outputs": [],
   "source": [
    "#@title Sample Solution (double-click to view) {display-mode: \"form\"}\n",
    "\n",
    "def guess_analogy(a,b,c,vectors,top_n=5):\n",
    "    \n",
    "# ------------- Exercise 6 -------------- #\n",
    "\n",
    "    inputs = set([a,b,c])\n",
    "    guess_vector = vectors[b] - vectors[a] + vectors[c]\n",
    "    guesses = glove.similar_by_vector(guess_vector)\n",
    "    return [item[0] for item in guesses if item[0] not in inputs][:top_n]\n",
    "\n",
    "# ---------------- End ------------------ #\n",
    "\n",
    "\n",
    "# quick test\n",
    "a,b,c,d = \"man\",\"king\",\"woman\",\"queen\"\n",
    "guesses = guess_analogy(a,b,c,glove)\n",
    "if d in guesses:\n",
    "    print(\"queen was in the top n guesses!\")\n",
    "else:\n",
    "    print(\"queen was NOT in the top n guesses...\")\n",
    "    print(\"guesses were:\",guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "itdJIVzb6ygH"
   },
   "source": [
    "- When you are ready, run your function on some more of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ldXrUbvN6wFI"
   },
   "outputs": [],
   "source": [
    "# evaluation\n",
    "\n",
    "# just check 100 per category, otherwise you will have to wait a while\n",
    "max_per_category = 100\n",
    "correct = collections.defaultdict(int)\n",
    "top_5_correct = collections.defaultdict(int)\n",
    "total = collections.defaultdict(int)\n",
    "for category, analogy_questions in analogies.items():\n",
    "    print(\"evaluating\",category)\n",
    "    for aq in analogy_questions[:max_per_category]:\n",
    "        a,b,c,d = aq\n",
    "        if all([item in glove for item in [a,b,c,d]]):\n",
    "            guesses = guess_analogy(a,b,c,glove)\n",
    "            total[category] += 1\n",
    "            if d in guesses:\n",
    "                top_5_correct[category] += 1\n",
    "                if d == guesses[0]:\n",
    "                    correct[category] += 1\n",
    "                \n",
    "global_correct = 0\n",
    "global_top_5_correct = 0\n",
    "global_total = 0\n",
    "print()\n",
    "print(\"Category-level results\")\n",
    "for category in analogies:\n",
    "    if total[category]:\n",
    "        print(category)\n",
    "        print(\"\\t\",\"top-1 score:\",float(correct[category])/total[category])\n",
    "        print(\"\\t\",\"top-5 score:\",float(top_5_correct[category])/total[category])\n",
    "        global_correct += correct[category]\n",
    "        global_top_5_correct += top_5_correct[category]\n",
    "        global_total += total[category]\n",
    "print(\"Overall results\")\n",
    "print(\"\\t\",\"top-1 score:\",float(global_correct)/global_total)\n",
    "print(\"\\t\",\"top-5 score:\",float(global_top_5_correct)/global_total)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oV8__Z_tBHKy"
   },
   "source": [
    "- Did you get better results than the sample solution?\n",
    "    - It achieved, overall:\n",
    "        - top-1: 0.46875\n",
    "        - top-5: 0.640625\n",
    "- What could you do to improve the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B_mAiar69XVS"
   },
   "source": [
    "---\n",
    "## B - Sub-words and Compositionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yc6DBleGGFYk"
   },
   "source": [
    "- You may have noticed that our word embeddings don't always work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "32cQtzvXCIN9"
   },
   "outputs": [],
   "source": [
    "# note that the current version of GloVe Twitter is about 5 years old now\n",
    "try:\n",
    "    print(glove['adulting'])\n",
    "except Exception as e:\n",
    "    print(\"Error:\",e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X1Okogf3IxO8"
   },
   "source": [
    "- How could we address this?\n",
    "- We could:\n",
    "    - skip words for which we do not have embeddings\n",
    "    - use the same \"out of vocabulary\" (OOV) vector to represent each unknown word.\n",
    "    - re-train our word embeddings every...\n",
    "        - year? month? day?\n",
    "    - change the unit of semantics from *words* to *something else*.\n",
    "        - What else might we choose?\n",
    "            - Some proposals include subwords, word pieces, and characters.\n",
    "- Let's consider the last approach, first by looking at subword embeddings with fasttext:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n1ExQY49CBvJ"
   },
   "source": [
    "### Sub-words embeddings with FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d5OrZZOvKDX8"
   },
   "outputs": [],
   "source": [
    "# we can also load these using gensim\n",
    "# this will also take several minutes to load into memory\n",
    "emb_path = \"crawl-300d-2M-subword.bin\"\n",
    "fasttext_model = fasttext.load_model(emb_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E2UI57GtMC4J"
   },
   "source": [
    "- We can do the same kinds of things that we did before with GloVe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tllsXn1XMGhg"
   },
   "outputs": [],
   "source": [
    "print(\"First 50 dimensions of vector for computer:\")\n",
    "print(fasttext_model['computer'][:50])\n",
    "\n",
    "print(\"Similarity between 'forest' and 'trees':\")\n",
    "print(1- scipy.spatial.distance.cosine(fasttext_model['forest'], fasttext_model['trees']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hd4YHEacRB6Y"
   },
   "source": [
    "- In addition, we can use subword information to reason about unknown words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VjH7U3gARHJ1"
   },
   "outputs": [],
   "source": [
    "print(\"First 50 dimensions of vector for adulting:\")\n",
    "print(fasttext_model['adulting'][:50])\n",
    "print()\n",
    "# just to prove that totally new words are handled\n",
    "print(\"First 50 dimensions of vector for howhoozaling:\")\n",
    "print(fasttext_model['howhoozaling'][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BnFyVLQ8CJM7"
   },
   "source": [
    "### Semantic compositions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JmBWd9yXL3xq"
   },
   "source": [
    "- Simply averaging word embeddings (mean pooling) turns out to be a strong baseline for short text representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ljAMMzl2CO1-"
   },
   "outputs": [],
   "source": [
    "sent1 = \"The airplane flew over the fields\"\n",
    "sent2 = \"A train crossed the river\"\n",
    "\n",
    "sent1_emb = np.mean([fasttext_model[w.lower()] for w in sent1.split()],axis=0)\n",
    "sent2_emb = np.mean([fasttext_model[w.lower()] for w in sent2.split()],axis=0)\n",
    "\n",
    "print(\"Similarity:\",1- scipy.spatial.distance.cosine(sent1_emb,sent2_emb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FOkb06JGCRc9"
   },
   "source": [
    "### Putting it together: short text similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rjqKfik8rfbE"
   },
   "source": [
    "- SemEval is a yearly competition to solve a range of semantic NLP tasks.\n",
    "- A common SemEval task is \"semantic text similarity\".\n",
    "    - The goal is to build a model that can produce similarity scores for pairs of texts that are highly correlated with human judgements of similarity.\n",
    "    - Let's load some data for this task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XHwjDInJsLtn"
   },
   "outputs": [],
   "source": [
    "test_sts_data = []\n",
    "fnames = ['section1','section2','section3','docid','score','doc1','doc2']\n",
    "with open(\"stsbenchmark/sts-test.csv\",'r') as infile:\n",
    "    reader = csv.DictReader(infile, fieldnames=fnames,dialect=csv.excel_tab)\n",
    "    for row in reader:\n",
    "        test_sts_data.append(row)\n",
    "print(\"Loaded\",len(test_sts_data),\"test pairs.\")\n",
    "print(\"Example:\",test_sts_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GO3Ui7vLsMKa"
   },
   "source": [
    "- Now, let's build a simple system to get some reasonable results on this task.\n",
    "    - hint: stopword removal should be helpful here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y7YJTljkCZyc"
   },
   "outputs": [],
   "source": [
    "def get_text_sim_score(text1,text2,word_embeddings):\n",
    "\n",
    "# ------------- Exercise 3 -------------- #\n",
    "\n",
    "\n",
    "\n",
    "# ---------------- End ------------------ #\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-1y4PvfMyMMt"
   },
   "outputs": [],
   "source": [
    "#@title Sample Solution (double-click to view) {display-mode: \"form\"}\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def get_text_sim_score(text1,text2,word_embeddings):\n",
    "\n",
    "# ------------- Exercise 3 -------------- #\n",
    "\n",
    "    vec1 = np.mean([word_embeddings[w] for w in text1.split() if w.lower() not in stopwords],axis=0)\n",
    "    vec2 = np.mean([word_embeddings[w] for w in text2.split() if w.lower() not in stopwords],axis=0)\n",
    "    score = 1 - scipy.spatial.distance.cosine(vec1,vec2)\n",
    "\n",
    "# ---------------- End ------------------ #\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p31HO9h5tYs5"
   },
   "source": [
    "- Let's evaluate the performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9CPvttc_tcoI"
   },
   "outputs": [],
   "source": [
    "golds, preds = [],[]\n",
    "for test_data in test_sts_data:\n",
    "    text1 = test_data['doc1']\n",
    "    text2 = test_data['doc2']\n",
    "    if text1 and text2:\n",
    "        gold = float(test_data['score'])\n",
    "        pred = get_text_sim_score(text1,text2,fasttext_model)\n",
    "        golds.append(gold)\n",
    "        preds.append(pred)\n",
    "\n",
    "print(\"Some examples of pairs and their human annotated scores:\")\n",
    "for item in test_sts_data[:5]:\n",
    "    print(item['score'],item['doc1'],item['doc2'])\n",
    "print(\"Correct labels:\",golds[:5])\n",
    "print(\"Predictions:\",preds[:5])\n",
    "print(\"Correlation Score (rho, p-value):\",scipy.stats.pearsonr(golds,preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uXc7bqB5SRLY"
   },
   "source": [
    "- That is a good start! \n",
    "- It's definitely possible to do better with different compisition functions/networks, or even this same approach with different embeddings.\n",
    "    - See some of the state-of-the-art results here: http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mHJks7U5ybrD"
   },
   "source": [
    "- [-> Next: Machine Learning](https://colab.research.google.com/github/gordeli/textanalysis/blob/master/colab/06_Text_Processsing_Basics_DS3Text.ipynb)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "05_Text_Embeddings_DS3Text.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
